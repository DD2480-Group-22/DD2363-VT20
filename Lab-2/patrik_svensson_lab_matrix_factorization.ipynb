{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of patrik-svensson_lab_matrix_algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "source": [
        "# **Lab2 : Matrix Factorization**\n",
        "**Patrik Svensson**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixOh5-9HXB0N",
        "colab_type": "text"
      },
      "source": [
        "In the field of linear algebra there is a commonly reoccuring problem that regards finding the unkonw $x$ vector in a linear equation $Ax = b$ where $A$ is a matrix, and $b$ is a vector. To solve this equation it is possible to mulitply the inverse of $A$ denoted by $A^{-1}$ on the left side on both side of the equations, this yields a new equation $x = A^{-1}b$. To find the inverse of $A$ can sometimes be troublesome and require a lot of time and computional power. Due to this, certain methods of how to efficiently find an inverse to a matrix have been introduced. The result of this report is an investigation and implementation of algorithms for matrix-vector multiplication with CRS, factorization of matrices, and a genral direct solver for linear equations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "source": [
        "To set up the environment, run the two following lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import unittest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "source": [
        "Trying to solve a linear equation can be a challenging task when working with matrices and vectors with lare-sized dimensions. A linear equation is given on the form of $Ax = b$, where $A$ is a given matrix, $b$ is a vector, and $x$ is the unknown solution to the equation in the shape of a vector. When we want to find a direct solution to a system of linear equations it is necessary to factorize the $A$ matrix into products of several matrices that are easy to invert. In this report I will focus on implementing algorithms for factorizing matrices in an computional efficient way. The following three functions are implemented.\n",
        "\n",
        "* Sparse matrix-vector product  \n",
        "* QR factorization\n",
        "* Direct solver Ax=b\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "source": [
        "# **Methods**\n",
        "In this chapter, I will present how the implementation of the functions was conducted. The study was conducted in the following way.\n",
        "\n",
        "1.   Literature research\n",
        "2.   Implementation\n",
        "3.   Testing\n",
        "\n",
        "In the sections below, I have provided a reference to where the algorithms were founded, or how it was deduced, followed with a code implementation in Python, and lastly unit test for the assurance of the accuracy of the implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0ouFDaAnMX",
        "colab_type": "text"
      },
      "source": [
        "## Sparse matrix-vector product\n",
        "The code is based on *Algorithm 5.9* pseudo-code in the lecture notes *Part III Matrix factorization*. Together with this, I have created a class to represent *CRS* datastructure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8i3MLmzA0fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRS():\n",
        "  def __init__(self, val_array, col_idx_array, row_ptr_array, m, n):\n",
        "    self.val_array = val_array\n",
        "    self.col_idx_array = col_idx_array\n",
        "    self.row_ptr_array = row_ptr_array\n",
        "    self.m = m\n",
        "    self.n = n\n",
        "\n",
        "  def val(self, index):\n",
        "      return self.val_array[index]\n",
        "\n",
        "  def row_ptr(self, index):\n",
        "    return self.row_ptr_array[index]\n",
        "\n",
        "  def col_idx(self, index):\n",
        "    return self.col_idx_array[index]\n",
        "\n",
        "def sparse_matrix_vector_product(x, A):\n",
        "  if A.m != x.shape[0] or x.ndim != 1:\n",
        "    raise ValueError(\"Illegal input\")\n",
        "\n",
        "  b = np.zeros(A.m)\n",
        "  for i in range(A.n):\n",
        "    for j in range(A.row_ptr(i), A.row_ptr(i+1)):\n",
        "      b[i] = b[i] + A.val(j) * x[A.col_idx(j)]\n",
        "  return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUeY0kSsof-D",
        "colab_type": "text"
      },
      "source": [
        "In the code below, I have provided code for assurance of the implemented functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m181nK-Or5mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestSparseMatrixVectorProduct(unittest.TestCase):\n",
        "  def test_incompatibledimensions_throwexception(self):\n",
        "    # Arrange\n",
        "    val = np.array([1,2])\n",
        "    col = np.array([0,1])\n",
        "    row_ptr = np.array([0, 1, 2])\n",
        "    m = 2\n",
        "    n = 2\n",
        "    x = np.array([1,2,3])\n",
        "\n",
        "    A = CRS(val, col, row_ptr, m, n)\n",
        "\n",
        "    # Assert, Act\n",
        "    self.assertRaises(ValueError, sparse_matrix_vector_product, x, A)\n",
        "\n",
        "  def test_simplematrix_correctmatrix(self):\n",
        "    # Arrange\n",
        "    val = np.array([1,2])\n",
        "    col = np.array([0,1])\n",
        "    row_ptr = np.array([0, 1, 2])\n",
        "    m = 2\n",
        "    n = 2\n",
        "    x = np.array([1,2])\n",
        "\n",
        "    A = CRS(val, col, row_ptr, m, n)\n",
        "\n",
        "    standard_matrix_representation = np.array([[1, 0],[0, 2]])\n",
        "    expected_result = standard_matrix_representation.dot(x)\n",
        "\n",
        "    # Act \n",
        "    returned_result = sparse_matrix_vector_product(x, A)\n",
        "    \n",
        "    #Assert\n",
        "    np.testing.assert_array_equal(returned_result, expected_result)\n",
        "\n",
        "  def test_3x3matrix_correctmatrix(self):\n",
        "    # Arrange\n",
        "    val = np.array([1,2,3,4,5])\n",
        "    col = np.array([1,1,2,0,1])\n",
        "    row_ptr = np.array([0,1,3,5])\n",
        "    m = 3\n",
        "    n = 3\n",
        "    x = np.array([12,4,7])\n",
        "\n",
        "    A = CRS(val, col, row_ptr, m, n)\n",
        "\n",
        "    standard_matrix_representation = np.array([[0,1,0],\n",
        "                                               [0,2,3],\n",
        "                                               [4,5,0]])\n",
        "    expected_result = standard_matrix_representation.dot(x)\n",
        "\n",
        "    # Act \n",
        "    returned_result = sparse_matrix_vector_product(x, A)\n",
        "    \n",
        "    #Assert\n",
        "    np.testing.assert_array_equal(returned_result, expected_result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "    # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63OKr80VH-vo",
        "colab_type": "text"
      },
      "source": [
        "## QR Factorization\n",
        "When it comes to QR factorization there exists two common different implementation methods:\n",
        "1. *Gram Schmidt*\n",
        "2. *Householder Refletions*\n",
        "3. *Givens Rotations*\n",
        "\n",
        "In this implementation I have chosen to create the *Gram Schmidt* version. The code is based on Algorithm 5.3 pseudo-code in the lecture notes *Part III Matrix factorization*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpM_nVqYJJFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def qr_factorization(A):\n",
        "  n = A.shape[0]\n",
        "  R = np.zeros((n,n))\n",
        "  Q = np.zeros((n,n))\n",
        "  v = np.zeros(n)\n",
        "\n",
        "  v[:] = A[:,0]\n",
        "\n",
        "  for i in range(n):\n",
        "    R[i,i] = np.linalg.norm(v)\n",
        "    Q[:,i] = v[:]/R[i,i]\n",
        "\n",
        "    for j in range(i+1, n):\n",
        "      R[i,j] = np.dot(Q[:,i], A[:,j])\n",
        "      v[:] = A[:,j] - R[i,j]*Q[:,i]\n",
        "\n",
        "  return R,Q "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTKuFPM83FjY",
        "colab_type": "text"
      },
      "source": [
        "In the code below I have provided unit tests for assuring the quality of the implemented function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVIgR4AO3lda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestQRFactorization(unittest.TestCase):\n",
        "  def test_upper_triangular_matrix(self):\n",
        "    # Arrange\n",
        "    A = np.array([[2,-1],\n",
        "              [-1, 2]])\n",
        "\n",
        "    # Act \n",
        "    R, Q = qr_factorization(A)\n",
        "\n",
        "    # Assert \n",
        "    self.assertTrue(np.allclose(R, np.triu(R)))\n",
        "\n",
        "  def test_forbenius_norms_one(self):\n",
        "    # Arrange\n",
        "    A = np.array([[2,-1],\n",
        "                [-1, 2]])\n",
        "    identity_matrix = np.identity(2)\n",
        "\n",
        "    # Act\n",
        "    R, Q = qr_factorization(A)\n",
        "\n",
        "\n",
        "    # Assert\n",
        "    temp = np.dot(Q,np.transpose(Q)) - identity_matrix\n",
        "    frobenius_norm = np.linalg.norm(temp, 'fro')\n",
        "\n",
        "    self.assertAlmostEqual(frobenius_norm, 0)\n",
        "\n",
        "  def test_forbenius_norms_two(self):\n",
        "    # Arrange\n",
        "    A = np.array([[2,-1],\n",
        "                [-1, 2]])\n",
        "    identity_matrix = np.identity(2)\n",
        "\n",
        "    # Act\n",
        "    R, Q = qr_factorization(A)\n",
        "\n",
        "\n",
        "    # Assert\n",
        "    frobenius_norm = np.linalg.norm(np.dot(Q, R) - A, 'fro')\n",
        "    self.assertAlmostEqual(frobenius_norm, 0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "  # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "  unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrLlK4pMIHJu",
        "colab_type": "text"
      },
      "source": [
        "## Direct solver Ax = b\n",
        "According to section 5.1 in the lecture note *Part III Matrix factorization* a *direct solution* is a when factorization method are used to build a product of several matrices from one single matrix in $Ax = b$ linear equations. This is beneficial because the products are easier to invert than the inital $A$ matrix. There are several different methods for how to factorize a matrix, and in the previous section I implemented the *Gram-Schmidt* method. Since it is already implemented it would be convient to use it as the base of my solver, hence given a linear equation on the form $Ax = b$, I want to use the *Gram-Schmidt* function to convert it to $x = A^{-1}b$ to solve the unknown variable x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRn0RNpgEB6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def direct_solver(A, b):\n",
        "  R,Q = qr_factorization(A)\n",
        "  inverted_R = np.linalg.inv(R)\n",
        "  inverted_Q = np.linalg.inv(Q)\n",
        "  inverted_A = np.dot(inverted_R, inverted_Q)\n",
        "  x = np.dot(inverted_A, b)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPWNC9YnEC-g",
        "colab_type": "text"
      },
      "source": [
        "In the code below, I have provided unit test to assert the correctness of the implemented algorithm in the code above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2bGB1xHES10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDirectSolver(unittest.TestCase):\n",
        "  def test1_residual_result_vector(self):\n",
        "    # Arrange\n",
        "    A = np.array([[2,-1],\n",
        "                  [-1, 2]])\n",
        "    b = np.array([2,2])\n",
        "    y = np.array([2,2])\n",
        "\n",
        "    # Act \n",
        "    x = direct_solver(A, b)\n",
        "\n",
        "    # Assert \n",
        "    np.testing.assert_array_almost_equal(0, np.linalg.norm(x - y))\n",
        "\n",
        "  def test2_residual_result_vector(self):\n",
        "    # Arrange\n",
        "    A = np.array([[1,1],\n",
        "              [1, 2]])\n",
        "    b = np.array([5,7])\n",
        "    y = np.array([3,2])\n",
        "\n",
        "    # Act \n",
        "    x = direct_solver(A, b)\n",
        "\n",
        "    # Assert \n",
        "    np.testing.assert_array_almost_equal(0, np.linalg.norm(x - y))\n",
        "\n",
        "  def test1_residual_Ax_and_b(self):\n",
        "    # Arrange\n",
        "    A = np.array([[2,-1],\n",
        "                  [-1, 2]])\n",
        "    b = np.array([2,2])\n",
        "    y = np.array([2,2])\n",
        "\n",
        "    # Act\n",
        "    x = direct_solver(A, b)\n",
        "    Ax = np.dot(A, x)\n",
        "\n",
        "    # Assert\n",
        "    np.testing.assert_array_almost_equal(0, np.linalg.norm(Ax - b))\n",
        "\n",
        "  def test2_residual_Ax_and_b(self):\n",
        "    # Arrange\n",
        "    A = np.array([[1,1],\n",
        "              [1, 2]])\n",
        "    b = np.array([5,7])\n",
        "    y = np.array([3,2])\n",
        "\n",
        "    # Act\n",
        "    x = direct_solver(A, b)\n",
        "    Ax = np.dot(A, x)\n",
        "\n",
        "    # Assert\n",
        "    np.testing.assert_array_almost_equal(0, np.linalg.norm(Ax - b))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "  # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "  unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "source": [
        "# **Results**\n",
        "All 10 test in the test runner below passes their asserts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EIji0rL755g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4ca26fb5-2d3d-4c03-e370-6feec153bcda"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "  # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "  unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........\n",
            "----------------------------------------------------------------------\n",
            "Ran 10 tests in 0.013s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "source": [
        "# **Discussion**\n",
        "\n",
        "The results from the previous chapter points towards that the algorithms are correctly implemented. But there's still more future work that can be done at algorithm implementation level to improve them. One suggested improvement is to add guards in the beginnning of the algorithms that preven wrong usage of the functions, such as provide wrong-sized matrices or vectors as arguments to the functions."
      ]
    }
  ]
}